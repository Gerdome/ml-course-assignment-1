{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in your name using the format below and student ID number\n",
    "your_name = \"LAST_NAME, FIRST_NAME\"\n",
    "student_id = \"YOUR_ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "We will study some more algorithms on the [Fashion-MNIST dataset](https://www.openml.org/d/40996).\n",
    "As we saw in the first lab session, it contains 70,000 images of fashion products, classified into 10 \n",
    "types of clothing, each represented by 28 by 28 pixel values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import openml\n",
    "import time\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download FMINST data. Takes a while the first time.\n",
    "fmnist = openml.datasets.get_dataset(40996)\n",
    "X, y, _, _ = fmnist.get_data(target=fmnist.default_target_attribute); \n",
    "fmnist_classes = {0:\"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\", 5: \"Sandal\", \n",
    "                  6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle boot\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting functions. Don't edit these.\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "\n",
    "def plot_live(X, y, evaluator, param_name, param_range, scale='log', ylim=(0,1), ylabel='score'):\n",
    "    \"\"\" Renders a plot that updates with every evaluation from evaluator.\n",
    "    Keyword arguments:\n",
    "    X -- the data for training and testing\n",
    "    y -- the correct labels\n",
    "    evaluator -- a function with signature (X, y, param_value) that returns a dictionary of scores.\n",
    "                 Examples: {\"train\": 0.9, \"test\": 0.95} or {\"model_1\": 0.9, \"model_2\": 0.7}\n",
    "    param_name -- the parameter that is being varied on the X axis. Can be a hyperparameter, sample size,...\n",
    "    param_range -- list of all possible values on the x-axis\n",
    "    scale -- defines which scale to plot the x-axis on, either 'log' (logarithmic) or 'linear'\n",
    "    ylim -- tuple with the lowest and highest y-value to plot (e.g. (0, 10))\n",
    "    ylabel -- the y-axis title\n",
    "    \"\"\"\n",
    "    # Plot interactively\n",
    "    plt.ion()\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(param_name)\n",
    "    \n",
    "    # Make the scale look nice\n",
    "    plt.xscale(scale)\n",
    "    plt.xlim(param_range[0],param_range[-1])\n",
    "    plt.ylim(ylim)\n",
    "        \n",
    "    # Start from empty plot, then fill it\n",
    "    series = {}\n",
    "    lines = {}\n",
    "    xvals = []\n",
    "    for i in param_range:\n",
    "        scores = evaluator(X, y, i) \n",
    "        if i == param_range[0]: # initialize series\n",
    "            for k in scores.keys():\n",
    "                lines[k], = plt.plot(xvals, [], marker = '.', label = k)\n",
    "                series[k] = []\n",
    "        xvals.append(i)\n",
    "        for k in scores.keys(): # append new data\n",
    "            series[k].append(scores[k])\n",
    "            lines[k].set_data(xvals, series[k])\n",
    "        # refresh plot\n",
    "        plt.legend(loc='best')\n",
    "        plt.margins(0.1)\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.1\n",
    "Implement a function `evaluate_SVM` that evaluates an SVM with RBF kernel for a given gamma value and returns the train and test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement\n",
    "def evaluate_SVM(X, y, gamma):\n",
    "    \"\"\" Evaluate an SVM with 5-fold cross-validation on the provided (X, y) data. \n",
    "    Keyword arguments:\n",
    "    X -- the data for training and testing\n",
    "    y -- the correct labels\n",
    "    gamma -- the value for the gamma parameter\n",
    "    \n",
    "    Returns: a dictionary with the mean train and test score, e.g. {\"train\": 0.9, \"test\": 0.95}\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function `plot_1` that plots the results of `evaluate_SVM` on a 1% stratified subsample of the FMNIST dataset for gamma values ranging from 1e-12 to 1e12 (25 values on a log scale). You can use the plotting functions `plot_live` defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement\n",
    "def plot_1():\n",
    "    pass\n",
    "plot_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2\n",
    "Interpret the graph. Answer the following questions with multiple choice:  \n",
    "- 'A': Underfitting\n",
    "- 'B': Overfitting\n",
    "- 'C': Neither underfitting nor overfitting\n",
    "- 'D': No answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the gamma value 1e-9, is the model over- or underfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the correct answer, e.g. 'A'. Don't change the name of the variable\n",
    "q_1_2_1 = 'D'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the gamma value 1e3, is the model over- or underfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the correct answer, e.g. 'A'. Don't change the name of the variable\n",
    "q_1_2_2 = 'D'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1\n",
    "Implement a function `time_SVM` that measures the train and predict time of an SVM with RBF kernel for a given sample size (training set size). Use the default gamma value. The same data can be used for training and prediction since we only care about the running time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement\n",
    "def time_SVM(X, y, sample_size):\n",
    "    \"\"\" Measure how long it takes to train a single SVM model and how fast it predicts. Run the algorithms on one core only.\n",
    "    Keyword arguments:\n",
    "    X -- the data for training and testing\n",
    "    y -- the correct labels\n",
    "    sample_size -- the percentage of the data that should be used for training and testing\n",
    "    \n",
    "    Returns: a dictionary with the measured time in seconds, e.g. {\"fit\": 12.1, \"predict\": 1.95}\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function `plot_2` that plots the results of `time_SVM` for a sample size between 0.001 and 0.05 of the full FMNIST dataset. Use at least 10 different values, on a log scale. You can again use the plotting functions `plot_live` defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement\n",
    "def plot_2():\n",
    "    pass\n",
    "plot_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2\n",
    "Interpret the graph. What do you observe?  \n",
    "- 'A': Fitting takes longer than predicting\n",
    "- 'B': Predicting takes longer than fitting\n",
    "- 'C': Fitting and predicting take exactly equally long\n",
    "- 'D': No answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the correct answer, e.g. 'A'. Don't change the name of the variable\n",
    "q_2_2 = 'D'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.3\n",
    "Run the plot again, but this time using a function `time_SVM_tuned` which is the same as `time_SVM` except that ot uses gamma=1e-5 rather than the default gamma value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement\n",
    "def time_SVM_tuned(X, y, sample_size):\n",
    "    \"\"\" Measure how long it takes to train a single SVM model and how fast it predicts. \n",
    "    Run the algorithms on one core only. Use stratified sampling to subsample the data.\n",
    "    Keyword arguments:\n",
    "    X -- the data for training and testing\n",
    "    y -- the correct labels\n",
    "    sample_size -- the percentage of the data that should be used for training and testing\n",
    "    \n",
    "    Returns: a dictionary with the measured time in seconds, e.g. {\"fit\": 12.1, \"predict\": 1.95}\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# Implement\n",
    "def plot_3():\n",
    "    pass\n",
    "plot_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.4\n",
    "What do you observe? Which differences do you see? For each difference, explain what may cause the effect. Answer inside the multi-line string. Use less than 400 characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in your answer\n",
    "q_2_4_answer = \"\"\"\n",
    "Type your answer here.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer is 24 characters long\n"
     ]
    }
   ],
   "source": [
    "# Check your answer's length\n",
    "print(\"Your answer is {} characters long\".format(len(q_2_4_answer))) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
